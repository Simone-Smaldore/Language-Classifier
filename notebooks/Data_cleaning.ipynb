{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad49c564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "from commons import DATASET_LOCATION, DATASET_CLEAN_LOCATION, DATASET_CLEAN_UNDERSAMPLING_LOCATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f829a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATASET_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac30d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iteng = df[(df['Language'] == 'Italian') | (df['Language'] == 'English')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abea67ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per prima cosa metto tutto in minuscolo. Poi sostituisco l'apostrofo con uno spazio (Altrimenti costrutti come l'uomo diventavano un unico token luomo)\n",
    "# Successivamente elimino i numeri e poi i caratteri non alfanumerici a parte gli spazi. Elimino infine gli spazi multipli in modo da avere solo uno spazio che divide le parole\n",
    "\n",
    "\n",
    "def clean_text_keep_accents(text):\n",
    "    cleaned = ''.join(\n",
    "        c for c in text\n",
    "        if (\n",
    "            # Tieni lettere o numeri o spazi\n",
    "            unicodedata.category(c).startswith(('L', 'N')) or c.isspace()\n",
    "        )\n",
    "        # Per eliminare i caratteri speciali che sono classificati come MODIFIER LETTER\n",
    "        and not unicodedata.name(c, '').startswith('MODIFIER')\n",
    "    )\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"'\", \" \")\n",
    "    text = ''.join(c for c in text if not c.isdigit())\n",
    "    text = ''.join(c for c in text if c.isalnum() or c.isspace())\n",
    "    #Pulizia dei caratteri unicode\n",
    "    text = clean_text_keep_accents(text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ce289ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iteng['Text_clean'] = df_iteng['Text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8236a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_iteng[[\"Text_clean\", \"Language\"]]\n",
    "df_clean = df_clean.rename(columns={\"Text_clean\": \"Text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28ea10e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv(DATASET_CLEAN_LOCATION, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0588c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Undersampling utilizzando i quartili\n",
    "df_iteng['Word_count'] = df_iteng['Text_clean'].apply(lambda x: len(str(x).split()))\n",
    "english_df = df_iteng[df_iteng['Language'] == 'English'].copy()\n",
    "english_df['quartile'] = pd.qcut(english_df['Word_count'], q=4, labels=False)\n",
    "\n",
    "undersampled_parts = []\n",
    "for q in range(4):\n",
    "    group = english_df[english_df['quartile'] == q]\n",
    "    sampled = group.sample(frac=0.5, random_state=1999)\n",
    "    undersampled_parts.append(sampled)\n",
    "english_undersampled = pd.concat(undersampled_parts)\n",
    "italian_df = df_iteng[df_iteng['Language'] == 'Italian']\n",
    "df_clean_undersampling = pd.concat([english_undersampled, italian_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b542bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_undersampling = df_clean_undersampling[[\"Text_clean\", \"Language\"]]\n",
    "df_clean_undersampling = df_clean_undersampling.rename(columns={\"Text_clean\": \"Text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d0ac501",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_undersampling.to_csv(DATASET_CLEAN_UNDERSAMPLING_LOCATION, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Language Classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad49c564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "import pandas as pd\n",
    "from commons import DATASET_CLEAN_LOCATION, DATASET_CLEAN_UNDERSAMPLING_LOCATION, DATASET_LOCATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c777fca",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "We import the dataset used in the data exploration phase and filter it to include only sentences in Italian and English.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f829a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATASET_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac30d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iteng = df[(df[\"Language\"] == \"Italian\") | (df[\"Language\"] == \"English\")].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e19ebc",
   "metadata": {},
   "source": [
    "The function `clean_text_keep_accents` is used within the main cleaning pipeline to filter out unwanted Unicode characters that the primary cleaning function might miss.\n",
    "\n",
    "Specifically, it removes all special characters except letters (including accented characters), numbers, and whitespace. It preserves accented letters by checking Unicode categories starting with \"L\" (letters) and \"N\" (numbers), while excluding characters categorized as modifier letters and punctuation. This ensures that important accented characters remain intact for languages like Italian, while unwanted symbols and special characters are removed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abea67ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_keep_accents(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean a string by removing special characters while preserving accents.\n",
    "\n",
    "    This function removes all characters from the input string except letters,\n",
    "    numbers, and whitespace. It retains accented characters and strips out\n",
    "    special symbols, including modifier letters and punctuation.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text string to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned text with accents preserved and special characters removed.\n",
    "\n",
    "    \"\"\"\n",
    "    return \"\".join(\n",
    "        c for c in text\n",
    "        if (\n",
    "            unicodedata.category(c).startswith((\"L\", \"N\")) or c.isspace()\n",
    "        )\n",
    "        and not unicodedata.name(c, \"\").startswith(\"MODIFIER\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bc2344",
   "metadata": {},
   "source": [
    "This function `clean_text` performs a series of preprocessing steps to clean and normalize the input text:\n",
    "\n",
    "- Converts the entire text to lowercase to ensure uniformity.\n",
    "- Replaces apostrophes with spaces to prevent contractions (e.g., \"l'uomo\" becomes two separate tokens: \"l\" and \"uomo\").\n",
    "- Removes all digits from the text.\n",
    "- Keeps only alphanumeric characters and whitespace, removing other punctuation.\n",
    "- Cleans remaining Unicode characters by calling `clean_text_keep_accents`, which preserves accented characters while removing unwanted symbols.\n",
    "- Normalizes whitespace by collapsing multiple spaces into a single space, ensuring consistent token separation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60135d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean and normalizes a text string by lowercasing, removing digits, and stripping punctuation.\n",
    "\n",
    "    This function performs several text preprocessing steps:\n",
    "    - Converts all characters to lowercase.\n",
    "    - Replaces apostrophes with spaces.\n",
    "    - Removes all digits.\n",
    "    - Keeps only alphanumeric characters and whitespace.\n",
    "    - Cleans remaining Unicode characters while preserving accents (via `clean_text_keep_accents`).\n",
    "    - Normalizes whitespace to ensure consistent spacing.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text string to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned and normalized text.\n",
    "\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"'\", \" \")\n",
    "    text = \"\".join(c for c in text if not c.isdigit())\n",
    "    text = \"\".join(c for c in text if c.isalnum() or c.isspace())\n",
    "    text = clean_text_keep_accents(text)\n",
    "    return  \" \".join(text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6360454",
   "metadata": {},
   "source": [
    "We apply the cleaning function to the dataset and save the cleaned version for the training phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ce289ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iteng[\"Text_clean\"] = df_iteng[\"Text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8236a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_iteng[[\"Text_clean\", \"Language\"]]\n",
    "df_clean = df_clean.rename(columns={\"Text_clean\": \"Text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28ea10e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv(DATASET_CLEAN_LOCATION, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70301784",
   "metadata": {},
   "source": [
    "We also create another dataset using undersampling because the English sentences are twice as many as the Italian ones. \n",
    "\n",
    "However, instead of random undersampling, we take half of the sentences from each of the four quartiles, where the quartiles are defined based on the word count of the sentences. This approach helps maintain the distribution of sentence lengths in the undersampled data.\n",
    "\n",
    "The steps are as follows:\n",
    "- Separate the English sentences and divide them into four quartiles based on their word counts.\n",
    "- From each quartile, randomly sample 50% of the sentences.\n",
    "- Combine the undersampled English sentences with all the Italian sentences.\n",
    "- Save this balanced dataset for the training phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0588c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iteng[\"Word_count\"] = df_iteng[\"Text_clean\"].apply(lambda x: len(str(x).split()))\n",
    "english_df = df_iteng[df_iteng[\"Language\"] == \"English\"].copy()\n",
    "english_df[\"quartile\"] = pd.qcut(english_df[\"Word_count\"], q=4, labels=False)\n",
    "\n",
    "undersampled_parts = []\n",
    "for q in range(4):\n",
    "    group = english_df[english_df[\"quartile\"] == q]\n",
    "    sampled = group.sample(frac=0.5, random_state=1999)\n",
    "    undersampled_parts.append(sampled)\n",
    "english_undersampled = pd.concat(undersampled_parts)\n",
    "italian_df = df_iteng[df_iteng[\"Language\"] == \"Italian\"]\n",
    "df_clean_undersampling = pd.concat([english_undersampled, italian_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b542bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_undersampling = df_clean_undersampling[[\"Text_clean\", \"Language\"]]\n",
    "df_clean_undersampling = df_clean_undersampling.rename(columns={\"Text_clean\": \"Text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d0ac501",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_undersampling.to_csv(DATASET_CLEAN_UNDERSAMPLING_LOCATION, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

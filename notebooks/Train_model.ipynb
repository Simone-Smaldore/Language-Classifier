{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f3a3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from commons import DATASET_CLEAN_LOCATION, DATASET_CLEAN_UNDERSAMPLING_LOCATION, MODEL_FOLDER\n",
    "from commons import Datasets\n",
    "from commons import split_dataset\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b567ba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATASET_CLEAN_LOCATION)\n",
    "df_undersampling = pd.read_csv(DATASET_CLEAN_UNDERSAMPLING_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350b6b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bow = split_dataset(df, CountVectorizer())\n",
    "df_bow_undersampling = split_dataset(df_undersampling, CountVectorizer())\n",
    "df_tfidf = split_dataset(df, TfidfVectorizer())\n",
    "df_tfidf_undersampling = split_dataset(df_undersampling, TfidfVectorizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0584d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(datasets: Datasets):\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(datasets.X, datasets.y)\n",
    "    y_pred = nb.predict(datasets.X_t)\n",
    "    print(\"Naive Bayes:\", accuracy_score(datasets.y_t, y_pred))\n",
    "    \n",
    "    wrong_idx = datasets.y_t != y_pred\n",
    "    errors_df = pd.DataFrame({\n",
    "        'Text': datasets.text_t[wrong_idx],         \n",
    "        'True Label': datasets.y_t[wrong_idx],\n",
    "        'Predicted Label': y_pred[wrong_idx]\n",
    "    })\n",
    "    print(errors_df)\n",
    "    return nb\n",
    "    \n",
    "def logistic_regression(datasets: Datasets):\n",
    "    param_grid = {\n",
    "        'C': [0.01, 0.1, 1, 10, 100, 1000, 10000], \n",
    "        'penalty': ['l2'],\n",
    "        'solver': ['lbfgs']\n",
    "    }\n",
    "    grid = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5, scoring='accuracy')\n",
    "    grid.fit(datasets.X, datasets.y)\n",
    "    \n",
    "    print(\"Best Params:\", grid.best_params_)\n",
    "    print(\"Best CV Accuracy:\", grid.best_score_)\n",
    "    \n",
    "    y_pred = grid.predict(datasets.X_t)\n",
    "    print(\"Logistic Regression:\", accuracy_score(datasets.y_t, y_pred))    \n",
    "    \n",
    "    wrong_idx = datasets.y_t != y_pred\n",
    "    errors_df = pd.DataFrame({\n",
    "        'Text': datasets.text_t[wrong_idx],         \n",
    "        'True Label': datasets.y_t[wrong_idx],\n",
    "        'Predicted Label': y_pred[wrong_idx]\n",
    "    })\n",
    "    print(errors_df)\n",
    "    \n",
    "    return grid\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4f01df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes: 0.9952038369304557\n",
      "                    Text  True Label  Predicted Label\n",
      "0         autorizzazione           1                0\n",
      "1  interrupting politely           0                1\n",
      "Naive Bayes: 0.9928057553956835\n",
      "          Text  True Label  Predicted Label\n",
      "0   scusandosi           1                0\n",
      "1  progettando           1                0\n",
      "Naive Bayes: 0.9952038369304557\n",
      "              Text  True Label  Predicted Label\n",
      "0   autorizzazione           1                0\n",
      "1  lasciami finire           1                0\n",
      "Naive Bayes: 0.9892086330935251\n",
      "                    Text  True Label  Predicted Label\n",
      "0             hesitating           0                1\n",
      "1  i m afraid i disagree           0                1\n",
      "2            suggestions           0                1\n"
     ]
    }
   ],
   "source": [
    "nb_bow = naive_bayes(df_bow)\n",
    "nb_bow_und = naive_bayes(df_bow_undersampling)\n",
    "nb_tfidf= naive_bayes(df_tfidf)\n",
    "nb_tfidf_und = naive_bayes(df_tfidf_undersampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb1d6d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best CV Accuracy: 0.9921975868083652\n",
      "Logistic Regression: 0.988009592326139\n",
      "                                                Text  True Label  \\\n",
      "0                                         permission           0   \n",
      "1                                        suggestions           0   \n",
      "2                              interrupting politely           0   \n",
      "3  cells within colonies became increasingly spec...           0   \n",
      "4                          in japanese copyright law           0   \n",
      "\n",
      "   Predicted Label  \n",
      "0                1  \n",
      "1                1  \n",
      "2                1  \n",
      "3                1  \n",
      "4                1  \n",
      "Best Params: {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best CV Accuracy: 0.9883206076031188\n",
      "Logistic Regression: 0.9784172661870504\n",
      "                                                Text  True Label  \\\n",
      "0        image files varies across language editions           0   \n",
      "1  cells within colonies became increasingly spec...           0   \n",
      "2                                         hesitating           0   \n",
      "3                              i m afraid i disagree           0   \n",
      "4                                        suggestions           0   \n",
      "5             your friends i m feeling very sluggish           0   \n",
      "\n",
      "   Predicted Label  \n",
      "0                1  \n",
      "1                1  \n",
      "2                1  \n",
      "3                1  \n",
      "4                1  \n",
      "5                1  \n",
      "Best Params: {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best CV Accuracy: 0.9927981874089659\n",
      "Logistic Regression: 0.9952038369304557\n",
      "              Text  True Label  Predicted Label\n",
      "0   autorizzazione           1                0\n",
      "1  lasciami finire           1                0\n",
      "Best Params: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best CV Accuracy: 0.9937098533511088\n",
      "Logistic Regression: 0.9856115107913669\n",
      "                                                Text  True Label  \\\n",
      "0  cells within colonies became increasingly spec...           0   \n",
      "1                                         hesitating           0   \n",
      "2                              i m afraid i disagree           0   \n",
      "3                                        suggestions           0   \n",
      "\n",
      "   Predicted Label  \n",
      "0                1  \n",
      "1                1  \n",
      "2                1  \n",
      "3                1  \n"
     ]
    }
   ],
   "source": [
    "lr_bow = logistic_regression(df_bow)\n",
    "lr_bow_und = logistic_regression(df_bow_undersampling)\n",
    "lr_tfidf = logistic_regression(df_tfidf)\n",
    "lr_tfidf_und = logistic_regression(df_tfidf_undersampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be9c2b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decido di salvare solo le combinazioni dei due modelli con bow e tfidf\n",
    "\n",
    "with open(f'{MODEL_FOLDER}/nb_bow.pkl', 'wb') as f:\n",
    "    pickle.dump(nb_bow, f)\n",
    "\n",
    "with open(f'{MODEL_FOLDER}/nb_tfidf.pkl', 'wb') as f:\n",
    "    pickle.dump(nb_tfidf, f)\n",
    "\n",
    "with open(f'{MODEL_FOLDER}/lr_bow.pkl', 'wb') as f:\n",
    "    pickle.dump(lr_bow, f)\n",
    "    \n",
    "with open(f'{MODEL_FOLDER}/lr_tfidf.pkl', 'wb') as f:\n",
    "    pickle.dump(lr_tfidf, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Language Classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
